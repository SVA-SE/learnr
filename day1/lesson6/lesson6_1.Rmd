[![Previous](../../img/previous.png)](../lesson5/lesson5_3.html)
[![Index](../../img/home.png)](../../index.html)
[![Next](../../img/next.png)](lesson6_2.html)
[![Folder](../../img/folder.png)](./)

---

# Work through examples from [Veterinary Epidemiologic Research](http://www.upei.ca/ver/) in R.

We will work through the examples from the chapter on 'Mixed models for
discrete data' (Pages 579-606) in the 2nd edition of the
[Veterinary Epidemiologic Research](http://www.upei.ca/ver/)
textbook. If you have the first edition of the same book the examples
are almost the same and are on pages 499-520.

```{r}
pig_adg<- read.csv("pig_adg.csv")

```

Example 22.1 on page 581 illustrates the analysis of the association
of atrophic rhinitis on pneumonia in pigs that are clustered in
farms.

Let's start by generating the necessary variables to do the analysis
that the authors have done.

The authors have given us the `pn` variable already, presence or
absence or pneumonia in the pig. We just need to generate the `ar_g1`
variable that is presence of atrophic rhinitis with a score greater
than 1.

```{r}
pig_adg$ar_g1 <- NA
pig_adg$ar_g1[pig_adg$ar > 1] <- 1
pig_adg$ar_g1[pig_adg$ar <= 1] <- 0
```

Then we can be neat and tidy and label the categorical variables that
we are going to use

```{r}
pig_adg$ar_g1 <- factor(pig_adg$ar_g1, levels = c(0,1), labels = c("no atrophic", "yes atrophic"))

pig_adg$pn <- factor(pig_adg$pn, levels = c(0,1), labels = c("no pneumonia", "mild-severe pneumonia"))

```

Now we can do the cross-tabulation that they did

```{r}
table(pig_adg$pn, pig_adg$ar_g1)

```

The authors also calculated odds ratio and tested the difference in
proportions in the groups with a chi-square test. We can do that
easily with the `epitools` library

## Contingency table

```{r}
library(epitools)

crosstab <- epitab(pig_adg$pn, pig_adg$ar_g1, pvalue = "chi2")
crosstab

```

From the above output we can see that the odds of a pig having
pneumonia is `r crosstab$tab[2, 5]` and that the calculated 95% confidence
interval around that estimate is also available (`r crosstab$tab[2, 6]` -
`r crosstab$tab[2, 7]`).
The _P_-value that corresponds to the chi-sq is given
(`r crosstab$tab[2, 8]`) but not chi-sq statistic itself. Note that
the confidence intervals and the _P_-values may not agree because the
methods that the authors have used are not clear

The next thing that is done is a logistic regression with a random
effect to adjust for the repeated measurement within farm. Before that,
we will do the regression without the random effect:

## Mixed effects logistic regression

```{r, warning = FALSE, message = FALSE}

model <- glm(pn ~ ar_g1, data = pig_adg, family = binomial)

summary(model)

```

Conveniently, in this function, we express the model in formula
notation and the function takes an argument for the name of the
dataset so you don't have to write ´data$variablename´ for each
variable you test. You also need to specify the model family, in this
case it is a logistic regression and therefore, binomial. You can also
confirm that the odds ratio from the cross tabulation that we did
agrees with the estimate from the model. The coefficient (log odds) on
Atrophic rhinitis is `r model$coefficients[2]` and therefore the Odds
ratio=
e^`r model$coefficients[2]`^ = `r exp(model$coefficients[2])`

Let's now add the random effect for farm, we need to use another
library `lme4` library to do this.

```{r, warning =FALSE, message = FALSE}

library(lme4)

model2 <- glmer(pn ~ ar_g1 + (1 | farm), data = pig_adg, family = binomial)

summary(model2)

```

Here you can see the notation used to add a random intercept to the
model. `(1 | farm)`. Now the coefficient on the atrophic rhinitis has
changed slightly after adjusting for the farm effect. The new adjusted
odds ratio is ratio=
e^`r model2@beta[2]`^ = `r exp(model2@beta[2])`, however the
estimate of the odds ratio is not significantly different from 1 as
indicated by the _P_-value = `r summary(model2)$coefficients[2,4]`.
Also in the example the variance of the farm random
effect is given. This is `r summary(model2)$varcor$farm[1]` and has a
standard error that is different than the value given in the book
because the method of calculation is different.

Now we will look at how to determine model fit by inspecting residuals
from a logistic model. First we will make the model more interesting
by adding another variable.

```{r}

model3 <- glmer(pn ~ ar_g1 + dtm  + (1 | farm), data = pig_adg, family = binomial)

```

You'll notice in the output that `lme4` asks us to consider rescaling
a variable in the model. If we want to do that, then we don't have to
generate a new dummy variable in the data frame (Although you could do
that too), can use a log function in the model call as follows:

```{r}

model4 <- glmer(pn ~ ar_g1 + log(dtm)  + (1 | farm), data = pig_adg, family = binomial)

```
or with the dummy variable:

```{r}

pig_adg$log_dtm <- log(pig_adg$dtm)

model5 <- glmer(pn ~ ar_g1 + log_dtm  + (1 | farm), data = pig_adg, family = binomial)

summary(model5)

```

If this was real life, I suppose we would consider the biological
plausibility of the model that we have generated and look at the
_P_-values and maybe throw out the ar_g1 variable and perhaps build a
linear regression with days to market as the outcome and pneumonia as
the independent variable.... This is just an example to teach you how
to use R, so try to forget about whether or not the biology or
modeling approach makes sense.

We need a dataframe of all the possible values of the covariates in
order to predict the outcomes for all levels

## Predictions from regression

```{r}

adg_predict <- expand.grid(ar_g1 = levels(pig_adg$ar_g1),
                           dtm   = seq(min(pig_adg$dtm), max(pig_adg$dtm)),
                           farm  = sort(unique(pig_adg$farm)))

adg_predict$log_dtm <- log(adg_predict$dtm)
```

Have a look at the first few lines of this prediction dataframe
```{r}
head(adg_predict)
```

Make the predictions based on the `model5` model. In this case the
`predict` function will use the `log_dtm` variable to do the
prediction in the `adg_predict` dataframe to calculate the predicted
log odds because the was the name of the variable when the model was specified.

```{r}

adg_predict$pred_model5 <- predict(model5, adg_predict)

```

We should get the same result if we do the prediction with `model4`
and internally the predictions will be calculated based on the `dtm`
variable and the `log` operation on the `dtm` value will be done by
the model.

```{r}

adg_predict$pred_model4 <- predict(model4, adg_predict)

```

Have a look at the first few rows of the prediction dataframe
`adg_predict`

```{r}

head(adg_predict)

```

## Plot predictions

First we can plot the predictions with one line for each random
intercept (each farm) and the lines coloured by the atrophic rhinitis
variable.

```{r}
library(ggplot2)

ggplot(adg_predict, aes(x = dtm, y = pred_model4, group = interaction(ar_g1, farm), colour = ar_g1)) +
    geom_line()

```

This illustrates the magnitude of the effect of herd compared to the
other variables in the model. Not I guess it's not too surprising that
the effect of atrophic rhinitis on pneumonia was not significant after
adjusting for farm. We can also just look at the model predictions for
an average farm. The shape of the model is the same for all farms
because we have no interactions with farm. Start by calculating the
mean predictions for each `dtm` and `ar_g1` level across farms:

```{r}

library(plyr)
prediction2 <- ddply(.data = adg_predict, .variables = c("dtm", "ar_g1"), .fun = function(x){mean(x$pred_model4)})

head(prediction2)
```

And plot this:

```{r}
ggplot(prediction2, aes(x = dtm, y = V1, group = ar_g1, colour = ar_g1)) +
    geom_line()

```

Maybe we want to view the predictions as predicted probability instead
of on the log odds scale

```{r}
prediction2$prob <- exp(prediction2$V1)/(1+exp(prediction2$V1))

ggplot(prediction2, aes(x = dtm, y = prob, group = ar_g1, colour = ar_g1)) +
    geom_line()

```
