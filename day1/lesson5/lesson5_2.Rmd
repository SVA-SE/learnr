---
output:
    html_document:
        css: ../../style.css
---

[![Previous](../../img/previous.png)](lesson5_1.html)
[![Index](../../img/home.png)](../../index.html)
[![Next](../../img/next.png)](lesson5_3.html)
[![Folder](../../img/folder.png)](./)

---

# Append data to a data.frame

To combine the 16 data files in this lesson, we will introduce the
[for-loop](https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Loops-and-conditional-execution). Using
the `for`, we can read one file at a time and append to the result. If
you browse the folder for this lesson, you should find the following
16 files.

```{r, comment = NA}
files <- c("herd_20.txt", "herd_21.txt", "herd_22.txt", "herd_23.txt",
           "herd_24.txt", "herd_25.txt", "herd_26.txt", "herd_27.txt",
           "herd_28.txt", "herd_30.txt", "herd_31.txt", "herd_33.txt",
           "herd_34.txt", "herd_36.txt", "herd_37.txt", "herd_38.txt")
```

Lets start to explore the `for` loop before reading data.

```{r, comment = NA}
for(i in 1:10) {
    cat("Hello R! ...")
}
```

The function `cat` spits out the characters in its argument to the
R-console. So you should see that R has done this 10 times, once for
each of the numbers (i) in the sequence from 1 to 10 which is what the
`i in 1:10` means.

In the above example we just do the same thing 10 times. You can also alter what you do each time it repeats by using the value of `i` inside the loop

```{r, comment = NA}
for(i in 1:10) {
    cat(i)
}
```

Here you can see that each time the loop iterates it returns the value
of `i`. This sequence of i's doesn't have to be numbers it could just
as well be our list of files.

Let's use our list of files to read the group of datasets into R using a loop

**\@Stefan: How are you planning to do this?**

I'm afraid that it is going to be too complicated. I can't do it without an empty list that I fill and then I will use do.call "rbind" OR lapply.

Below is pseudocode:

```{r, eval = FALSE}

for(i in files) {
    object_name with index <- read.csv(i)
}
```

Maybe instead of splitting the file into 16 herds you can split into 3 datasets that we have to stick together?
